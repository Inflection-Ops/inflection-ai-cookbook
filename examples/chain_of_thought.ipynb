{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_response, get_context\n",
    "from inference import fetch as fetch_inflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Intent Recognition for Service Routing using Chain-of-Thought Reasoning and Inflection AI API**\n",
    "\n",
    "This notebook demonstrates how to implement **intent recognition** for a **Service Router** using **Chain-of-Thought (CoT) reasoning**. The goal is to classify user intents and generate structured responses that optimize service routing. \n",
    "\n",
    "## **Overview**\n",
    "\n",
    "- Utilizes **Chain-of-Thought prompting** to enhance intent classification and decision-making.\n",
    "- Employs a **guiding instruction prompt** for consistent and structured output.\n",
    "- The model performs the following tasks:\n",
    "  - Extracts **user intent** by identifying the appropriate **service category** based on query and intent history.\n",
    "  - Provides a **reasoning trace** before making a classification.\n",
    "  - Outputs results in **XML format** for downstream automation.\n",
    "  - Utilizes the **`inflection_3_productivity` model**, optimized for task-specific classification like intent recognition.\n",
    "\n",
    "By leveraging **structured prompting and reasoning**, this approach improves **accuracy** and ensures **efficient, interpretable routing**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_api = False # True if using the old API, False if using the new OpenAI compatible API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example 1**\n",
    "Instruct the model to think deeply and use complex reasoning around emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"inflection_3_productivity\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction_prompt = \"\"\"\n",
    "Your task Is to sell to a customer. The customer might express unclear feelings and be not motivated.\n",
    "Think deeply, step by step, wrap your thought process inside <think></think> tags to contemplate the best way to approach the task with emotional intelligence, compassion and the need to close the sale. Consider potential edge cases of customer feelings. Then provide your message to the customer.\n",
    "Selling: On-prem AI deployments for LLMs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test: test_complex_eq_reasoning\n",
      "+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_context() got an unexpected keyword argument 'legacy_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m test_complex_eq_reasoning()\n",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m, in \u001b[0;36mtest_complex_eq_reasoning\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      5\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mI don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt really know if we can handle AI on-prem, we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have staff to support datacenter deployment. It is a hard decision.\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_instruction_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustomer:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegacy_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_inflection(context, model\u001b[38;5;241m=\u001b[39mmodel, legacy_api\u001b[38;5;241m=\u001b[39mlegacy_api)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_context() got an unexpected keyword argument 'legacy_api'"
     ]
    }
   ],
   "source": [
    "async def test_complex_eq_reasoning():\n",
    "    print(\"Starting test: test_complex_eq_reasoning\")\n",
    "    print(\"+*\"*20)\n",
    "    \n",
    "    user_query = \"\"\"\n",
    "    I don't really know if we can handle AI on-prem, we don't have staff to support datacenter deployment. It is a hard decision.\n",
    "    \"\"\"\n",
    "\n",
    "    context = get_context(system_instruction_prompt, user_query, user_input_label=\"Customer:\", legacy_api=legacy_api)\n",
    "    result = await fetch_inflection(context, model=model, legacy_api=legacy_api)\n",
    "    print(f\"{result}\")\n",
    "    \n",
    "\n",
    "# Run the test\n",
    "await test_complex_eq_reasoning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example 2**\n",
    "The **XML output** format enables seamless integration with automation pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction_prompt = \"\"\"\n",
    "You are an AI assistant designed to determine the correct service intent for routing a user's query. Follow a step-by-step approach based on the sequence of prior intents and the user's current input.\n",
    "\n",
    "## Your Task:\n",
    "1. You will be provided with a sequence of previously identified service intents.\n",
    "2. You will also be provided with the user's current query.\n",
    "3. Your task is to analyze both pieces of information and determine the most appropriate next service intent.\n",
    "\n",
    "# Service Intent Definitions:\n",
    "- check_account_balance: Retrieve the user's account balance.\n",
    "- transfer_money: Transfer funds between accounts.\n",
    "- check_transaction_status: Check the status of a past transaction.\n",
    "- search_nearby_restaurants: Find nearby restaurants.\n",
    "- view_restaurant_reviews: Retrieve reviews for a restaurant.\n",
    "- book_table: Make a reservation at a restaurant.\n",
    "- search_flights: Look up available flights.\n",
    "- select_flight: Choose a flight.\n",
    "- enter_passenger_details: Provide passenger information for a flight.\n",
    "- retrieve_flight_information: Get details about a flight.\n",
    "- search_product: Find a product.\n",
    "- add_to_cart: Add a product to the shopping cart.\n",
    "- apply_discount: Apply a discount code to the cart.\n",
    "\n",
    "# Output Format (XML):\n",
    "You will respond in a valid XML format with the <parts>, <reasoning>, and <intent> tags following below output format. You don't need to provide explanation or any other information, just return reasoning and intent.\n",
    "- Reasoning: A short explanation of why this intent was chosen.\n",
    "- Intent: The determined service intent.\n",
    "\n",
    "# Format of the Output\n",
    "<parts>\n",
    "    <reasoning>The reasoning behind selecting this intent</reasoning>\n",
    "    <intent>determined_service</intent>\n",
    "</parts>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example_previous_intents_1 = \"check_account_balance -> transfer_money\"\n",
    "example_previous_user_query_1 = \"Can you confirm if the transfer was successful?\"\n",
    "example_output_1 = \"\"\"\n",
    "    <parts>\n",
    "        <reasoning>Can you confirm if the transfer was successful?\"\n",
    "        example_reasoning_1 = \"The user has already requested to transfer funds. Now, they are asking about the status of that transfer. This query is related to checking the transaction status.</reasoning>\n",
    "        <intent>check_transaction_status</intent>\n",
    "    </parts>\n",
    "\"\"\"\n",
    "\n",
    "example_previous_intents_2 = \"search_nearby_restaurants -> view_restaurant_reviews\"\n",
    "example_previous_user_query_2 = \"Can you book a table for 7 PM?\"\n",
    "example_output_2 = \"\"\"\n",
    "    <parts>\n",
    "        <reasoning>The user started by searching for restaurants and then viewed reviews. Now, they are asking to reserve a table at one of the restaurants. This query is related to making a reservation.</reasoning>\n",
    "        <intent>book_table</intent>\n",
    "    </parts>\n",
    "\"\"\"\n",
    "\n",
    "example_previous_intents_3 = \"search_flights -> select_flight -> enter_passenger_details\"\n",
    "example_previous_user_query_3 = \"What are the baggage policies for this airline?\"\n",
    "example_output_3 = \"\"\"\n",
    "    <parts>\n",
    "        <reasoning>What are the baggage policies for this airline?\"\n",
    "        example_reasoning_3 = \"The user has already selected a flight and entered passenger details. Now, they are asking for additional information about the flight's baggage policy. This query is related to retrieving flight details.</reasoning>\n",
    "        <intent>retrieve_flight_information</intent>\n",
    "    </parts>\n",
    "\"\"\"\n",
    "\n",
    "example_previous_intents_4 = \"search_product -> add_to_cart\"\n",
    "example_previous_user_query_4 = \"Can you apply a discount code for me?\"\n",
    "example_output_4 = \"\"\"\n",
    "    <parts>\n",
    "        <reasoning>The user has added a product to their cart and now wants to apply a discount. This query is related to applying a coupon or promotion.</reasoning>\n",
    "        <intent>apply_discount</intent>\n",
    "    </parts>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_router_context(previous_intents: str, service_request: str, legacy_api: bool=True) -> list:\n",
    "    \"\"\"\n",
    "    Returns the context for the service router.\n",
    "    \"\"\"\n",
    "\n",
    "    if legacy_api:\n",
    "        context = [\n",
    "            {\"type\": \"Instruction\", \"text\": system_instruction_prompt},\n",
    "\n",
    "            {\"type\": \"Human\", \"text\": example_previous_intents_1},\n",
    "            {\"type\": \"Human\", \"text\": example_previous_user_query_1},\n",
    "            {\"type\": \"AI\", \"text\": example_output_1},\n",
    "\n",
    "            {\"type\": \"Human\", \"text\": example_previous_intents_2},\n",
    "            {\"type\": \"Human\", \"text\": example_previous_user_query_2},\n",
    "            {\"type\": \"AI\", \"text\": example_output_2},\n",
    "\n",
    "            {\"type\": \"Human\", \"text\": example_previous_intents_3},\n",
    "            {\"type\": \"Human\", \"text\": example_previous_user_query_3},\n",
    "            {\"type\": \"AI\", \"text\": example_output_3},\n",
    "\n",
    "            {\"type\": \"Human\", \"text\": example_previous_intents_4},\n",
    "            {\"type\": \"Human\", \"text\": example_previous_user_query_4},\n",
    "            {\"type\": \"AI\", \"text\": example_output_4},\n",
    "            {\n",
    "                \"type\": \"Human\",\n",
    "                \"text\": f\"Query: {previous_intents}\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Human\",\n",
    "                \"text\": f\"Query: {service_request}\",\n",
    "            },\n",
    "        ]\n",
    "    else:\n",
    "        context = [\n",
    "                {\"role\": \"system\", \"content\": system_instruction_prompt},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": example_previous_intents_1},\n",
    "                {\"role\": \"user\", \"content\": example_previous_user_query_1},\n",
    "                {\"role\": \"assistant\", \"content\": example_output_1},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": example_previous_intents_2},\n",
    "                {\"role\": \"user\", \"content\": example_previous_user_query_2},\n",
    "                {\"role\": \"assistant\", \"content\": example_output_2},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": example_previous_intents_3},\n",
    "                {\"role\": \"user\", \"content\": example_previous_user_query_3},\n",
    "                {\"role\": \"assistant\", \"content\": example_output_3},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": example_previous_intents_4},\n",
    "                {\"role\": \"user\", \"content\": example_previous_user_query_4},\n",
    "                {\"role\": \"assistant\", \"content\": example_output_4},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Query: {previous_intents}\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Query: {service_request}\",\n",
    "                },\n",
    "            ]\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scenario: Intent Recognition for Service Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_service_router():\n",
    "    print(\"Starting test: test_service_router\")\n",
    "    print(\"+*\"*20)\n",
    "    previous_intents = \"search_nearby_restaurants\"\n",
    "    service_request = \"Please show me the reviews.\"\n",
    "    context = get_service_router_context(previous_intents, service_request, legacy_api=legacy_api)\n",
    "    result = await get_response(context, [\"reasoning\", \"intent\"], legacy_api=legacy_api)\n",
    "\n",
    "    assert result[\"intent\"] == \"view_restaurant_reviews\"\n",
    "    print(f\"{color.BOLD} Intent recognized: {color.END} {result[\"intent\"]}\")\n",
    "    print(f\"{color.BOLD} Reasoning: {color.END} {result[\"reasoning\"]}\")\n",
    "    print(\"+*\"*20)\n",
    "\n",
    "    previous_intents = \"search_flights -> select_flight\"\n",
    "    service_request = \"Used auto saved information to fill out the details.\"\n",
    "    context = get_service_router_context(previous_intents, service_request, legacy_api=legacy_api)\n",
    "    result = await get_response(context, [\"reasoning\", \"intent\"], legacy_api=legacy_api)\n",
    "\n",
    "    assert result[\"intent\"] == \"enter_passenger_details\"\n",
    "    print(f\"{color.BOLD} Intent recognized:{color.END} {result[\"intent\"]}\")\n",
    "    print(f\"{color.BOLD} Reasoning: {color.END} {result[\"reasoning\"]}\")\n",
    "    print(\"+*\"*20)\n",
    "\n",
    "    previous_intents = \"search_product -> add_to_cart\"\n",
    "    service_request = \"I have a discount code ABCD1234. Please apply to this order.\"\n",
    "    context = get_service_router_context(previous_intents, service_request, legacy_api=legacy_api)\n",
    "    result = await get_response(context, [\"reasoning\", \"intent\"], legacy_api=legacy_api)\n",
    "\n",
    "    assert result[\"intent\"] == \"apply_discount\"\n",
    "    print(f\"{color.BOLD} Intent recognized: {color.END} {result[\"intent\"]}\")\n",
    "    print(f\"{color.BOLD} Reasoning: {color.END} {result[\"reasoning\"]}\")\n",
    "    print(\"+*\"*20)\n",
    "\n",
    "    print(\"All tests passed successfully! 🙌\")\n",
    "\n",
    "# Run the test\n",
    "await test_service_router()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
